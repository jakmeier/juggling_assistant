# Meeting notes Sunday 18th of July

Discussed topics:
- Valentin presented an overview of state prediction modelling
- We discussed assumptions and limitations we want to use (at least at the start)

## Assumptions
- Camera is fixed and does not move
- We ignore camera distortion for now
- Z coordinate (depth) is not estimated or modelled
- We don't attempt to deal with collisions
- Initial goal is to measure the number of throws and the height of them (rather than pattern detection)

## Model
- The video input goes through a computer vision (CV) pipeline and feeds X and Y measurements to the model
- Our model would have one prediction per video frame
- We can model each ball with four state variables (x/y position and velocity) with a linear prediction
- Using the time between the highest and the lowest point, we can compute the distance in meter and estimate the relation between meters and pixels (linear for a start)
- Depending how good our measurement is, the model may or may not contribute a lot
- Open questions:
    * Each catch/throw resets the model state. How to cope with that?

## Conclusion
- We should start with a simple CV pipeline that just maps an image to X,Y measurements, without any state modelling
- To simplify further, let's start with an object that is easy to detect (e.g. ball with single color) so that we can expect high accuracy measurements and don't need a model at all
- The purpose of this first pipeline is mostly to get the project up and running

## Actions
- Jakob: Video with simple object
- Valentin: Think about what framework to use